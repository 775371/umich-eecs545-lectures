{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import imp\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops\n",
    "\n",
    "def trim(im, percent=36):\n",
    "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
    "    diff = ImageChops.difference(im, bg)\n",
    "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox:\n",
    "        x = im.crop(bbox)\n",
    "        return x.resize(((x.size[0]*percent)/100, (x.size[1]*percent)/100), Image.ANTIALIAS)\n",
    "\n",
    "def resize(filename, percent=36):\n",
    "    trim(Image.open(filename + \".png\"), percent).save(filename + \"_r\" + str(percent) + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EECS 545:  Machine Learning\n",
    "## Lecture 20:  Neural Networks\n",
    "* Instructor:  **Junhyuk Oh**\n",
    "* Date:  April 6, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - Natural Language Processing\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limitations of Linear Classifiers\n",
    "\n",
    "- Linear classifiers (e.g., logistic regression) classify inputs based on linear combinations of input $x_i$\n",
    "- Many decisions involve non-linear functions of the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "trim(Image.open('linear.png'), 70).save('linear_resize.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limitations of Linear Classifiers\n",
    "- Canonical example (XOR function)\n",
    "  - The positive/negative examples are not *linearly separable*.\n",
    "  - Need to map the input ($x_1,x_2$) to a feature space where examples are linearly separable.\n",
    "![a](linear_resize.png)\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Raquel Urtasun & Rich Zemel)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Representation\n",
    "![a](motorbike_1.png)\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Slide Credit: Honglak Lee)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Representation\n",
    "![a](motorbike_2.png)\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Slide Credit: Honglak Lee)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hand-crafted Feature Representation\n",
    "![a](hand_crafted_pipeline.png)\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Slide Credit: Honglak Lee)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Drawbacks of Hand-crafted Feature Representation\n",
    "- Requires expert knowledge\n",
    "- Requires time-consuming hand-tuning <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Q) Can we learn useful features from raw data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\rightarrow$ Yes. That's what **deep learning** is trying to do. <br />\n",
    "$\\rightarrow$ **Deep neural network** is one of the popular deep learning approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- **Basics of Neural Networks**\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - Natural Language Processing\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "resize(\"images/nn\", 50)\n",
    "resize(\"images/nn\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overview of Neural Networks\n",
    "- Input Layer: provides input\n",
    "- Hidden Layer: features extracted from input\n",
    "- Output Layer: output of the network\n",
    "<img src=\"images/nn.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overview of Neural Networks\n",
    "- A **loss function** is defined over the *output units* and *desired outputs* (i.e., labels)\n",
    "$$\\mathcal{L}\\left( \\textbf{y}, \\hat{\\textbf{y}} \\right) \\mbox{ where } \\hat{\\textbf{y}}=f(\\textbf{x};\\theta) $$\n",
    "- The parameter of the network is trained to minimize the loss function based on gradient descent methods\n",
    "$$\\min_{\\theta} \\mathbb{E}_{(\\textbf{x},\\textbf{y}) \\sim \\mbox{data}} \\left[ \\mathcal{L}\\left( \\textbf{y}, \\hat{\\textbf{y}} \\right) \\right] \\mbox{ where } \\hat{\\textbf{y}}=f(\\textbf{x};\\theta) $$\n",
    "    <img src=\"images/nn.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overview of Neural Networks\n",
    "- Forward Propagation (inference): Compute $\\hat{\\textbf{y}}=f(\\textbf{x};\\theta)$ (output given input) \n",
    "- Backward Propagation (learning): Compute $\\nabla_{\\theta}\\mathcal{L}$ (gradient of loss w.r.t. parameters) \n",
    "    <img src=\"images/nn.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - **Forward Propagation**\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - Natural Language Processing\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "resize(\"images/nn_forward\", 50)\n",
    "resize(\"images/nn_forward2\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forward Propagation\n",
    "<img src=\"images/nn_forward.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forward Propagation\n",
    "<img src=\"images/nn_forward2.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forward Propagation\n",
    "- The activation of each unit is computed based on **the previous layer** and **parameters (or weights)** associated with edges\n",
    "$$\\underbrace{\\textbf{h}^{(l)}}_{l\\mbox{-th layer}}=f^{(l)}(\\underbrace{\\textbf{h}^{(l-1)}}_{(l-1)\\mbox{-th layer}}; \\underbrace{\\theta^{(l)}}_{\\mbox{weights}})$$\n",
    "$$\\hat{\\textbf{y}}=f(\\textbf{x};\\theta)=f^{(L)} \\circ f^{(L-1)} \\cdots f^{(2)} \\circ f^{(1)}\\left(\\textbf{x} ; \\theta^{(1)} \\right) $$\n",
    "<img src=\"images/nn.png\" width=500px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "resize(\"images/linear\", 60)\n",
    "resize(\"images/activation\", 60)\n",
    "resize(\"images/softmax\", 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Types of Layers: Linear\n",
    "$$ h_i=\\sum_{j}w_ijx_j + b_i$$\n",
    "$$ \\textbf{h} = \\textbf{W}\\textbf{x} + \\textbf{b} $$ \n",
    "- $\\textbf{x} \\in \\mathbb{R}^m $ : Input, $\\textbf{h} \\in \\mathbb{R}^n $ : Output\n",
    "- $\\textbf{W} \\in \\mathbb{R}^{n \\times m}$ : Weights, $\\textbf{b} \\in \\mathbb{R}^{n}$ : Bias\n",
    "- Often called \"fully-connected layer\"\n",
    "<img src=\"images/linear.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Types of Layers: Non-linear Activation Function\n",
    "- Makes neural networks learn non-linear features.\n",
    "- Applied to individual units without any weights.\n",
    "- ex) Sigmoid, Hyperbolic Tangent, Rectified Linear Function\n",
    "<img src=\"images/activation.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Non-linear Activation: Sigmoid\n",
    "$$ h_i=\\sigma (x_i) = \\frac{1}{1+\\exp\\left(-x_i\\right)} $$\n",
    "$$ \\textbf{h} = \\sigma \\left(\\textbf{x} \\right) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbfc251efd0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIS5/w/noOvqX8X0eQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbfc256df10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx = np.linspace(-5, 5, 100)\n",
    "plt.plot(xx, 1/(1 + np.exp(-1 * xx)), '-g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Non-linear Activation: Hyperbolic Tangent (Tanh)\n",
    "$$ h_i= \\mbox{tanh}(x_i)=\\frac{\\exp(x_i)-\\exp(-x_i)}{\\exp(x_i)+\\exp(-x_i)} $$\n",
    "$$ \\textbf{h} = \\mbox{tanh} \\left(\\textbf{x} \\right) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbfc23d5590>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvYhIxKnoRUQiTkUvIhJxKnoRkYj7/x5ye6oELH4vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbfc24d0310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx = np.linspace(-5, 5, 100)\n",
    "plt.plot(xx, (np.exp(xx) - np.exp(-1 * xx))/(np.exp(xx) + np.exp(-1 * xx)), '-g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Non-linear Activation: Rectified Linear (ReLU)\n",
    "$$ h_i= \\mbox{ReLU}(x_i)=\\max\\left(x_i, 0 \\right) $$\n",
    "$$ \\textbf{h} = \\mbox{ReLU} \\left(\\textbf{x} \\right) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbfc2306410>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEACAYAAACeQuziAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbfc24d0490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx = np.linspace(-5, 5, 100)\n",
    "plt.plot(xx, xx * (xx > 0).astype(np.int), '-g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Types of Layers: Softmax\n",
    "$$ h_i = \\frac{\\exp(x_i)}{\\sum_{j}\\exp(x_j)} $$\n",
    "$$ \\textbf{h} = \\mbox{Softmax}(\\textbf{x}) $$\n",
    "- Note: $h_i \\geq 0$ and $\\sum_{i}h_i=1$\n",
    "- Useful for generating a multinomial distribution (classification)\n",
    "![a](images/softmax_r60.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Types of Losses: Squared Loss\n",
    "$$ \\mathcal{L}\\left(\\textbf{y},\\hat{\\textbf{y}}\\right) = \\frac{1}{2}\\left\\Vert \\textbf{y}-\\hat{\\textbf{y}}\\right\\Vert^2_2 $$\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial \\hat{y}_i}=\\hat{y}_i-y_i $$\n",
    "$$ \\nabla_{\\hat{\\textbf{y}}}\\mathcal{L}=\\hat{\\textbf{y}}-\\textbf{y} $$\n",
    "- Used for regression problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Types of Losses: Cross Entropy\n",
    "$$ \\mathcal{L}\\left(\\textbf{y},\\hat{\\textbf{y}}\\right) = -\\sum_{i}y_i\\log\\hat{y}_i $$\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial \\hat{y}_i}=-\\frac{y_i}{\\hat{y}_i} $$\n",
    "$$ \\nabla_{\\hat{\\textbf{y}}}\\mathcal{L}=-\\frac{\\textbf{y}}{\\hat{\\textbf{y}}}$$\n",
    "\n",
    "- Measure distance between two multinomial distributions\n",
    "- Used for classification problems\n",
    "- Softmax layer is used as the output layer in general.\n",
    "  - ex) $\\textbf{y}=$[0 0 1], $\\hat{\\textbf{y}}=$[0.3 0.2 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "resize(\"images/mlp\", 60)\n",
    "resize(\"images/mlp_standard\", 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multi-layer Neural Network\n",
    "- Consists of multiple (linear + non-linear activation) layers.\n",
    "- Each layer learns a non-linear feature from its previous layer.\n",
    "- Often called Multi-Layer Perceptron (MLP).\n",
    "- 2-layer MLP with infinite number of hidden units can approximate any arbitrary function.\n",
    "<img src=\"images/mlp.png\" width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multi-layer Neural Network\n",
    "- Simplified illustration that only shows edges with weights.\n",
    "- We assume that each layer is followed by a non-linear activation function (except for the output layer).\n",
    "<img src=\"images/mlp_standard.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multi-layer Neural Network\n",
    "- More simplified illustration\n",
    "<img src=\"images/mlp_simple.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multi-layer Neural Network\n",
    "- Even more simplified illustration\n",
    "<img src=\"images/mlp_simplest.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - **Backward Propagation**\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - Natural Language Processing\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training Neural Networks\n",
    "- Repeat until convergence\n",
    "  - $(\\textbf{x},\\textbf{y}) \\leftarrow$ Sample an example (or a mini-batch) from data\n",
    "  - $\\hat{\\textbf{y}} \\leftarrow f\\left( \\textbf{x} ; \\theta \\right)$ Forward propagation\n",
    "  - Compute $\\mathcal{L}\\left(\\textbf{y},\\hat{\\textbf{y}}\\right)$\n",
    "  - $\\nabla_{\\theta}\\mathcal{L} \\leftarrow$ Backward propagation\n",
    "  - Update weights using (stochastic) gradient descent\n",
    "      - $\\theta \\leftarrow \\theta - \\alpha \\nabla_{\\theta}\\mathcal{L}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training Neural Networks\n",
    "<img src=\"images/forward_backward.png\" width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Idea of Back-Propagation\n",
    "- Denote $x,h,\\theta$ is the input, output, and parameter of a layer.\n",
    "- It is non-trivial to derive the gradient of loss w.r.t. parameters in intermediate layers\n",
    "![a](images/idea_backprop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Idea of Back-Propagation\n",
    "- Assuming that $\\frac{\\partial \\mathcal{L}}{\\partial h}$ is given, use the **chain rule** to compute the gradients\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\theta}=\\frac{\\partial \\mathcal{L}}{\\partial h}\\frac{\\partial h}{\\partial \\theta} \\mbox{ , } \\frac{\\partial \\mathcal{L}}{\\partial x}=\\frac{\\partial \\mathcal{L}}{\\partial h}\\frac{\\partial h}{\\partial \\theta}$$\n",
    "- Why compute $\\frac{\\partial \\mathcal{L}}{\\partial x}$? \n",
    "  - The previous layer needs it because $x$ is the output of the previous layer.\n",
    "![a](images/idea_backprop2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Idea of Back-Propagation\n",
    "<img src=\"images/nn_backward.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Idea of Back-Propagation\n",
    "<img src=\"images/nn_backward_2.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Idea of Back-Propagation\n",
    "<img src=\"images/nn_backward_3.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Idea of Back-Propagation\n",
    "<img src=\"images/nn_backward_4.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Back-Propagation Algorithm\n",
    "- Compute $\\nabla_{\\textbf{y}} \\mathcal{L}=\\left[\\frac{\\partial\\mathcal{L}}{\\partial y_1}, ..., \\frac{\\partial\\mathcal{L}}{\\partial y_n}\\right]$ directly from the loss function.\n",
    "- For each layer (from top to bottom) with output $\\textbf{h}$, input $\\textbf{x}$, and weights $\\textbf{W}$,\n",
    "  - Assuming that $\\nabla_{\\textbf{h}}\\mathcal{L}$ is given, compute gradients using the **chain rule** as follows: \n",
    "$$\\nabla_{\\textbf{x}}\\mathcal{L}=\\nabla_{\\textbf{h}}\\mathcal{L}\\nabla_{\\textbf{x}}\\textbf{h}$$\n",
    "$$\\nabla_{\\textbf{W}}\\mathcal{L}=\\nabla_{\\textbf{h}}\\mathcal{L}\\nabla_{\\textbf{W}}\\textbf{h}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "resize(\"images/linear_back\", 50)\n",
    "resize(\"images/activation_back\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Practice: Linear\n",
    "$$ h_i=\\sum_{j}w_{ij}x_j + b_i \\iff  \\textbf{h} = \\textbf{W}\\textbf{x} + \\textbf{b}$$ \n",
    "- Gradient w.r.t. parameters\n",
    "$$ \\frac{\\partial \\mathcal{L}}{\\partial w_{ij}} = \\frac{\\partial \\mathcal{L}}{\\partial h_{i}}\\frac{\\partial h_i}{\\partial w_{ij}}=\\frac{\\partial \\mathcal{L}}{\\partial h_{i}}x_j \\iff \\nabla_{\\textbf{W}} \\mathcal{L} = \\nabla_{\\textbf{h}}\\mathcal{L}\\textbf{x}^{\\top}$$\n",
    "$$ \\nabla_{\\textbf{b}} \\mathcal{L} = \\nabla_{\\textbf{h}}\\mathcal{L} $$\n",
    "- Gradient w.r.t. inputs\n",
    "$$ \\frac{\\partial \\mathcal{L}}{\\partial x_{j}} = \\sum_{i} \\frac{\\partial \\mathcal{L}}{\\partial h_{i}}\\frac{\\partial h_i}{\\partial x_{j}}=\\sum_{i} \\frac{\\partial \\mathcal{L}}{\\partial h_{i}}w_{ij} \\iff \\nabla_{\\textbf{x}} \\mathcal{L} = \\textbf{W}^{\\top}\\nabla_{\\textbf{h}}\\mathcal{L} $$\n",
    "<img src=\"images/linear_back.png\" width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Practice: Sigmoid\n",
    "$$ h_i=\\sigma (x_i) = \\frac{1}{1+\\exp\\left(-x_i\\right)} \\iff \\textbf{h} = \\sigma \\left(\\textbf{x} \\right) $$ \n",
    "\n",
    "- Gradient w.r.t. inputs\n",
    "$$ \\frac{\\partial \\mathcal{L}}{\\partial x_{i}} = \\frac{\\partial \\mathcal{L}}{\\partial h_{i}}\\frac{\\partial h_i}{\\partial x_{i}}=\\frac{\\partial \\mathcal{L}}{\\partial h_{i}}\\sigma(x_i)(1-\\sigma(x_i))=\\frac{\\partial \\mathcal{L}}{\\partial h_{i}}h_i(1-h_i)$$\n",
    "$$ \\nabla_{\\textbf{x}} \\mathcal{L} = \\nabla_{\\textbf{h}}\\mathcal{L} \\odot \\textbf{h} \\odot (\\textbf{1} - \\textbf{h}) $$\n",
    "<img src=\"images/activation_back.png\" width=400px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example Code (Torch/Lua)\n",
    "```lua\n",
    "require \"torch\"\n",
    "require \"nn\"\n",
    "\n",
    "dataX = torch.Tensor(1000, 3)\n",
    "dataY = torch.Tensor(1000):random(2)\n",
    "for iter=1,10000 do\n",
    "    -- sample an example from a dataset\n",
    "    idx = torch.random(1000)\n",
    "    x = dataX[idx]\n",
    "    y = dataY[idx]\n",
    "    -- network construction\n",
    "    model = nn.Sequential()\n",
    "    model:add(nn.Linear(3,4))\n",
    "    model:add(nn.Sigmoid())\n",
    "    model:add(nn.Linear(4,3))\n",
    "    model:add(nn.Sigmoid())\n",
    "    model:add(nn.Linear(3,2))\n",
    "    model:add(nn.LogSoftMax())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```lua\n",
    "    -- loss function (cross entropy)\n",
    "    criterion = nn.ClassNLLCriterion() \n",
    "    -- forward propagation\n",
    "    y_pred = model:forward(x)\n",
    "    loss = criterion:forward(y_pred, y)\n",
    "    -- backward propagation\n",
    "    model:zeroGradParameters() -- dL/dW = 0\n",
    "    -- compute dL/dy\n",
    "    dL_dy = criterion:backward(y_pred, y) \n",
    "    -- compute gradient w.r.t. weights\n",
    "    model:backward(x, dL_dy) \n",
    "    -- SGD update with learning rate of 0.001\n",
    "    model:updateParameters(0.001) \n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FAQ: Does neural network always have to be layer-structured?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- No. It can be any direcred acyclic graph (DAG).\n",
    "- Example of a complex neural network\n",
    "<img src=\"images/dag.png\" width=300px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FAQ: How to define a new type of layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can define any type of layer as lon g as it is differentiable.\n",
    "- Example) Addition layer\n",
    "  - Forward: $\\textbf{h} = \\textbf{x}_1 + \\textbf{x}_2$\n",
    "  - Backward\n",
    "    - $\\nabla_{\\textbf{x}_1}\\mathcal{L} = \\nabla_{\\textbf{h}}\\mathcal{L}\\nabla_{\\textbf{x}_1}\\textbf{h}=\\nabla_{\\textbf{h}}\\mathcal{L}$\n",
    "    - $\\nabla_{\\textbf{x}_2}\\mathcal{L} = \\nabla_{\\textbf{h}}\\mathcal{L}\\nabla_{\\textbf{x}_2}\\textbf{h}=\\nabla_{\\textbf{h}}\\mathcal{L}$\n",
    "<img src=\"images/addition.png\" width=500px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "resize(\"images/weight_sharing\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FAQ: How to handle shared weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To constrain $W_1=W_2=W$, we need $\\Delta W_1 = \\Delta W_2$.\n",
    "- Compute $\\nabla_{W_1}\\mathcal{L}$ and $\\nabla_{W_2}\\mathcal{L}$ separately.\n",
    "- Use $\\nabla_{W}\\mathcal{L}=\\nabla_{W_1}\\mathcal{L}+\\nabla_{W_2}\\mathcal{L}$ to update the shared weight.\n",
    "- In practice, we accumulate gradients to the shared memory space for $\\nabla_{W}\\mathcal{L}$ during back-propagation.\n",
    "- Weight sharing is used in *convolutional neural networks* and *recurrent neural networks*.\n",
    "<img src=\"images/weight_sharing.png\" width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- **Deep Neural Networks**\n",
    "  - Convolutional Neural Networks\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - Natural Language Processing\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is \"deep\" neural network?\n",
    "- A neural network is considered to be **deep** if it has more than two (non-linear) hidden layers.\n",
    "- Hidden layers discover useful features directly from raw inputs.\n",
    "- Higher layers learn more abstract and hierarchical features.\n",
    "  - In a classification network, features become more **linearly-separable** as layer goes up\n",
    "<img src=\"images/deep_nn.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is \"deep\" neural network?\n",
    "- Difficulties in training deep neural networks\n",
    "  - Easy to overfit (The number of parameters is large)\n",
    "  - Hard to optimize (highly non-convex optimization)\n",
    "  - Computationally expensive (many matrix multiplications)\n",
    "- Recent Advances\n",
    "  - Large-scale dataset (e.g., 1M images in ImageNet)\n",
    "  - Better regularization (e.g., Dropout)\n",
    "  - Better optimization (e.g., RMSProp, ReLU) \n",
    "  - Better hardware (GPU for matrix computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Popular Deep Architectures\n",
    "- Convolutional Neural Network (CNN)\n",
    "  - Widely used for image modeling\n",
    "  - ex) object recognition, segmentation, vision-based reinforcement learning problems\n",
    "- Recurrent Neural Network (RNN)\n",
    "  - Widely used for sequential data modeling\n",
    "  - ex) machine translation, image caption generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - **Convolutional Neural Networks**\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - Natural Language Processing\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Network\n",
    "- A special kind of multi-layer neural network\n",
    "- Designed to recognize visual patterns directly from raw pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "resize(\"images/cnn_ex1\", 40)\n",
    "resize(\"images/cnn_ex2\", 40)\n",
    "resize(\"images/cnn_ex3\", 50)\n",
    "resize(\"images/cnn_ex4\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multi-layer Perceptron (MLP)\n",
    "- Consider 100x100 input pixels\n",
    "- 1 hidden layer with 10000 hidden units\n",
    "- **100M parameters** $\\rightarrow$ infeasible!\n",
    "$\\rightarrow$ Pixels are locally correlated!\n",
    "<img src=\"images/cnn_ex1.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Locally-connected Neural Network\n",
    "- Consider 100x100 input pixels\n",
    "- Each unit is connected to 10x10 pixels.\n",
    "- 10000 hidden units\n",
    "- **1M parameters** $\\rightarrow$ still too large\n",
    "- Each unit extracts a local pattern from the image.\n",
    "<img src=\"images/cnn_ex2.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Network (one filter)\n",
    "- Consider 100x100 input pixels\n",
    "- Apply the **same filter (weight)** over the entire image.\n",
    "- Hidden units form a 100x100 **feature map**.\n",
    "- 10x10 parameters. <br />\n",
    "$\\rightarrow$ **only captures a single local pattern.**\n",
    "<img src=\"images/cnn_ex3.png\" width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Network (multiple filters)\n",
    "- 100x100 input pixels\n",
    "- Apply K number of 10x10 filters. \n",
    "- Hidden units form a Kx100x100 feature map.\n",
    "- Kx10x10 parameters. <br />\n",
    "<img src=\"images/cnn_ex4.png\" width=800px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "resize(\"images/convolution_multi\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Typical Deep CNN Architecture\n",
    "<img src=\"images/typical_cnn.png\" width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Details of Convolution\n",
    "<img src=\"images/convolution_step1.png\" width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Details of Convolution: Convolutional Filtering\n",
    "- A filter has $\\textbf{W} \\in \\mathbb{R}^{h \\times w}$ weights (bias is omitted for simplicity).\n",
    "- Compute inner products between $\\textbf{W}$ and $h \\times w$ input patches by sliding window.\n",
    "  - The same weight is shared across the entire image.\n",
    "- Apply $K$ different filters $\\rightarrow$ produces a 3D feature map (stacked through channels).\n",
    "- The following animation shows the simplest case: one-channel input, one filter\n",
    "![](images/convolution.gif)\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Stanford UFLDL Tutorial)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Details of Convolution: Convolutional Filtering\n",
    "- In general, an input consists of multiple channels.\n",
    "  - Each filter has $\\textbf{W} \\in \\mathbb{R}^{c \\times h \\times w}$ weight ($c$: \\#channels of input).\n",
    "- Hyperparameters: num of filters, size of filters\n",
    "- The general case: multi-channel input, mutilple filters\n",
    "<img src=images/convolution_multi.png width=500px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Stanford UFLDL Tutorial)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Details of Convolution: Non-linearity\n",
    "- Method: Just apply non-linear function (e.g., Sigmoid, ReLU)\n",
    "- ReLU is preferred because it makes optimization easier.\n",
    "<img src=\"images/convolution_step2.png\" width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Details of Convolution: Pooling\n",
    "<img src=\"images/convolution_step3.png\" width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Details of Convolution: Pooling\n",
    "- Method: Take average or maximum over the input feature.\n",
    "- Outcome\n",
    "  - Shrink the number of hidden units.$\\rightarrow$ reduces the number of parameters at the end.\n",
    "  - Make features robust to small translations of image.\n",
    "- Hyperparameters: pooling method (avg or max), pooling size\n",
    "- Often called \"sub-sampling\"\n",
    "<img src=images/pooling.gif width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Illustration of Deep CNN\n",
    "- Feature map becomes smaller in the higher layer due to pooling.\n",
    "- A hidden unit in higher layer captures a pattern from a larger input patch.\n",
    "<img src=images/deep_cnn.png />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Yann LeCun)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example Code (Torch/Lua)\n",
    "```lua\n",
    "require \"torch\"\n",
    "require \"nn\"\n",
    "model = nn.Sequential()\n",
    "-- 1st convolution: 3 -> 64 (5x5 filters)\n",
    "model:add(nn.SpatialConvolution(3, 64, 5, 5))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "-- 2nd convolution: 64 -> 64 (5x5 filters)\n",
    "model:add(nn.SpatialConvolution(64, 64, 5, 5))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "-- 3rd linear: 64*5*5 -> 128 hidden units\n",
    "-- Reshape 3D map to a long vector\n",
    "model:add(nn.View(64*5*5)) \n",
    "model:add(nn.Linear(64*5*5, 128))\n",
    "model:add(nn.ReLU())\n",
    "-- 4th linear: 128 -> 10 classes\n",
    "model:add(nn.Linear(128, 10))\n",
    "model:add(nn.LogSoftMax()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is learned by CNN? Filter Visualization\n",
    "- Train a deep CNN on *ImageNet* (1.2M images, 1000 classes)\n",
    "- Perform forward propagations from many examples\n",
    "- Find image patches that strongly activates a specific feature map (filter)\n",
    "- Reconstruct the input patch from the feature map\n",
    "- Proposed by Zeiler and Fergus (ECCV 2014)\n",
    "<img src=images/deep_cnn.png />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Yann LeCun)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Filter Visualization: 1st and 2nd Layer\n",
    "<img src=images/cnn_visualization1.png width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Filter Visualization: 3rd Layer\n",
    "- Shows more complex patterns\n",
    "<img src=images/cnn_visualization2.png width=1000px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Filter Visualization: 4th Layer\n",
    "- More class-specific\n",
    "<img src=images/cnn_visualization3.png width=1000px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Filter Visualization: 5th Layer\n",
    "- Shows entire objects with pose variations\n",
    "- Each filter can be viewed as a part detector. (e.g., dog face, text, animal leg)\n",
    "<img src=images/cnn_visualization4.png width=1000px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparison to Traditional Approach\n",
    "<img src=images/cnn_comparison.png width=1000px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ImageNet Classification 2012\n",
    "- AlexNet (7 layers, Krizhevsky et al.) achieves 16.4% error.\n",
    "- The next best model (non-CNN) achieves 26.2% error.\n",
    "![](images/imagenet.jpg)\n",
    "![](images/alexnet.png)\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Alex Krizhevsky et al.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ImageNet Classification\n",
    "- ImageNet 2013: Clarifi (7 layers) $\\rightarrow$ 14.8% error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ImageNet 2014: GoogLeNet (22 layers) $\\rightarrow$ 4.9% error (Human: 5.1% error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ImageNet 2015: ResNet (152 layers!) $\\rightarrow$ 3.5% error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Generalization: Dataset\n",
    "- Pre-train a CNN on a large-scale dataset (ImageNet) and **train only the final linear layer** on another dataset.\n",
    "- Achieves state-of-the-art results on small datasets (e.g., Caltech-101).\n",
    "- The learned features can generalize to any dataset.\n",
    "<img src=images/cnn_generalization1.png width=900px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Generalization: Task\n",
    "- Use high-level features as input for other tasks.\n",
    "<img src=images/cnn_generalization2.png width=900px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Generalization: Task\n",
    "- Achieves state-of-the-art results on many other vision tasks.\n",
    "  -  ex) object detection, segmentation, depth map prediction, image caption generation\n",
    "- A CNN trained on large-scale classification dataset learns a generic feature that can be used for many different vision tasks.\n",
    "<img src=images/cnn_generalization3.png width=900px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary of CNN\n",
    "- Convolutional Neural Network: a special kind of neural network with local connectivity and weight sharing.\n",
    "- Achieves state-of-the-art performances on many different tasks\n",
    "- Higher layers extract high-level features (e.g., dog).\n",
    "- Learned features can be generalized to other datasets and tasks."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
