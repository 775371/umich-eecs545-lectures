{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EECS 545:  Machine Learning\n",
    "## Lecture 11:  Bias-Variance Tradeoff, Cross Validation, ML Advice\n",
    "* Instructor:  **Jacob Abernethy**\n",
    "* Date:  February 22, 2015\n",
    "\n",
    "*Lecture Exposition Credit: Valli & Ben*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Today's Lecture: * Machine Learning Advice * \n",
    "- How does one go about choosing and applying an ML algorithm?\n",
    "- How does one improve the performance of an ML algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A Question to Ponder\n",
    "#### What is the goal of Machine Learning and ML algorithms?\n",
    "\n",
    "Common Goal:\n",
    "   - Not to learn an exact representation of the training data itself. \n",
    "   - Build a statistical model of the process which generates the data (Statistical Inference).\n",
    "   - This is important if the algorithm is to have good generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### At the beginning...\n",
    "\n",
    "- Suppose you are given some dataset and are asked to analyze it\n",
    "    - research project, data science job, homework assignment...\n",
    "- What is the first thing you will do once you are given this task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mysterious Data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(1000, n_features=5, n_informative=2, \n",
    "                           n_redundant=2, n_classes=2, random_state=0)\n",
    "\n",
    "from pandas import DataFrame\n",
    "df = DataFrame(np.hstack((X, y[:, None])), \n",
    "               columns = list(range(5)) + [\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = df.boxplot(return_type='dict')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Where to start?\n",
    "\n",
    "Analyze the data and preprocess using simple statistical measurements and tools. Look for:\n",
    " - Number of features? Number of classes? (for classification)\n",
    " - Mean, Median, Mode?\n",
    " - Correlation? \n",
    " - Dataset size? Missing samples?\n",
    " - Are samples labeled?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Visualization\n",
    "\n",
    "**Pro:** Can often be more useful than mathematical statistical analysis to get a good grasp of what the dataset looks like.\n",
    "- *\"Big Picture\"* view\n",
    "\n",
    "**Con:** High-dimensional data can be hard to visualize.\n",
    "- Projections may be misleading.\n",
    "\n",
    "Visualizations of the *mysterious dataset* follow..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pairwise Feature Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Pairwise feature plot\n",
    "_ = sns.pairplot(df[:50], vars=[0, 1, 2, 3, 4], hue=\"class\", size=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Correlation Plot\n",
    "plt.figure(figsize=(10, 10));\n",
    "_ = sns.heatmap(df.corr(), annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### General Approaches to a Data Problem\n",
    "\n",
    "After doing some visualization and simple statistical analysis or preprocessing of data, how should one proceed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approach 1: Careful Design \n",
    "- Things to do:\n",
    " - Engineer/Select exactly the right features.\n",
    " - Collect the right dataset.\n",
    " - Design the right algorithms.\n",
    "- Implement and hope it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approach 1:  Careful Design\n",
    "\n",
    "- Pros: \n",
    " - Can lead to new, elegant and scalable algorithms. \n",
    " - Contributions to ML theory are generally done using this approach.\n",
    "- Cons: \n",
    " - Can be time consuming. Slow time to market for companies. \n",
    " - \"Premature optimization is the root of all evil.\" - Donald Knuth (Note: while this quote was intended to talk about programming, premature statistical optimization can also be quite evil.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approach 2: Build and Fix\n",
    "- Implement something quickly.\n",
    "- Run error analyses and diagnoses to see if anything can be improved. Repeat until some performance criteria is met or goal is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approach 2:  Build and Fix\n",
    "\n",
    "Pros: \n",
    "- Easy especially with vast computing resources (can try different methods more easily). \n",
    "- Fast time to market.\n",
    "\n",
    "Cons: \n",
    "- Not systematic. \n",
    "- Can miss out on the reasoning behind why a model works well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choosing a Method\n",
    "\n",
    "Not easy to immediately decide what to use. Some things to consider first: \n",
    "- Supervised vs. Unsupervised vs. Semi-supervised vs. Active Learning vs. Reinforcement Learning ...?\n",
    "- Generative vs. Discriminative? \n",
    "- Parametric vs. Non-parametric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choosing a Method\n",
    "\n",
    "Still wondering how to go about choosing methods from an applied viewpoint? \n",
    " - There are many guides (see next few slides). \n",
    " - Go ahead and try different algorithms! (Similar to approach 2) We will also talk about how to measure performance and deal with poor performance later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/sklearn_sheet.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images/azure_sheet.png', width=800, height=600) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Break time!\n",
    "<img src=\"https://img.buzzfeed.com/buzzfeed-static/static/2013-10/enhanced/webdr01/15/9/anigif_enhanced-buzz-31540-1381844535-8.gif\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistical Inference\n",
    "## Loss Functions & Bias-Variance Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimators\n",
    "\n",
    "- ML Algorithms can in general be thought of as \"estimators.\"\n",
    "> **Estimator:** A statistic (a function of data) that is used to infer the value of an unknown parameter in a statistical model.\n",
    "\n",
    "- Suppose there is a fixed parameter $f$ that needs to be estimated. An estimator of $f$ is a function that maps the sample space to a set of sample estimates, denoted $\\hat{f}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Noise\n",
    "\n",
    "- For most problems in Machine Learning, the relationship is functional but noisy.\n",
    "\n",
    "- Mathematically, $y = f(x) + \\epsilon$\n",
    "    - $\\epsilon$ is noise with mean $0$ variance $\\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mathematical Viewpoint\n",
    "\n",
    "- Let the training set be $D = \\{\\mathbf{x}_1, ..., \\mathbf{x}_n\\}, \\mathbf{x}_i \\in \\mathbb{R}^d$.\n",
    "- **Goal:** Find $\\hat{f}$ that minimizes some **Loss function**, $L(y, \\hat{f})$, which measures how good predictions are for **both** \n",
    " - Points in $D$ (the **sample**), and, \n",
    " - Points ***out of sample*** (outside $D$).\n",
    "- Cannot minimize both perfectly because the relationship between $y$ and $\\mathbf{x}$ is noisy.\n",
    " - ***Irreducible error***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loss Functions\n",
    "\n",
    "There are many loss functions, each with their own use cases and interpretations.\n",
    "\n",
    "- **Quadratic Loss:**  $L(y,\\hat{f}) = (y-\\hat{f})^2$\n",
    "- **Absolute Loss:**  $L(y,\\hat{f}) = |y-\\hat{f}|$\n",
    "\n",
    "Classification-only loss functions:\n",
    "- **Sigmoid Loss:**  $L(y,\\hat{f}) = \\mathrm{sigmoid}(-y\\hat{f})$\n",
    "- **Zero-One Loss:**  $L(y,\\hat{f}) = \\mathbb{I}(y \\neq \\hat{f})$\n",
    "- **Hinge Loss:**  $L(y,\\hat{f}) = \\max(0, 1-y\\hat{f})$\n",
    "- **Logistic Loss:**  $L(y,\\hat{f}) = \\log[ 1 + \\exp(-y\\hat{f})]$\n",
    "- **Exponential Loss:**  $L(y,\\hat{f}) = \\exp[ -y \\hat{f} ]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choosing a Loss Function\n",
    "\n",
    "Different loss functions answer the following questions differently:\n",
    "\n",
    "- How should we treat **outliers**?\n",
    "- How **\"correct\"** do we need to be?\n",
    "    - Do we want a **margin** of safety?\n",
    "- What is our notion of **distance**?  What are we predicting?\n",
    "    - Real-world measurements?\n",
    "    - Probabilities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quadratic Loss (aka Square Loss)\n",
    "\n",
    " - Commonly used for regression\n",
    " - Heavily influenced by outliers\n",
    " \n",
    "$$\n",
    "L(y, \\hat{f}) = (y - \\hat{f})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100);\n",
    "plt.plot(x, x**2)\n",
    "plt.xlabel(\"$y-\\hat{f}$\", size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Absolute Loss\n",
    "\n",
    "- Commonly used for regression.\n",
    "- Robust to outliers.\n",
    "\n",
    "$$\n",
    "L(y, \\hat{f}) = |y - \\hat{f}|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Absolute Loss:  Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100);\n",
    "plt.plot(x, np.abs(x));\n",
    "plt.xlabel(\"$y-\\hat{f}$\", size=18);\n",
    "plt.ylabel(\"$|y-\\hat{f}|$\", size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 0-1 Loss\n",
    "\n",
    " - Used for classification. \n",
    " - Not convex! \n",
    "  - Not practical since optimization problems become intractable!\n",
    "  - \"Surrogate Loss functions\" that are convex and differentiable can be used instead.\n",
    "  \n",
    "$$\n",
    "L(y, \\hat{f}) = \\mathbb{I}(y \\neq \\hat{f})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sigmoid Loss\n",
    "\n",
    " - Differentiable but non-convex! Can be used for classification.\n",
    " \n",
    "$$L(y,\\hat{f}) = \\mathrm{sigmoid}(-y\\hat{f})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-6, 6, 100);\n",
    "plt.plot(x, 1/(1 + np.exp(-x)));\n",
    "plt.xlabel(\"$-y\\hat{f}$\", size=18);\n",
    "plt.ylabel(\"$\\sigma(-y\\hat{f})$\", size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic Loss\n",
    "\n",
    " - Used in Logistic regression.\n",
    " - Influenced by outliers. \n",
    " - Provides well calibrated probabilities (can be interpreted as confidence levels).\n",
    " \n",
    "$$L(y,\\hat{f}) = \\log[ 1 + \\exp(-y\\hat{f})]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-6, 6, 100);\n",
    "plt.plot(x, np.log2(1 + np.exp(-x)));\n",
    "plt.xlabel(\"$-y\\hat{f}$\", size=18);\n",
    "plt.ylabel(\"$\\log(1 + \\exp(-y\\hat{f}))$\", size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hinge Loss\n",
    "\n",
    " - Used in SVMs. \n",
    " - Robust to outliers.\n",
    " - Doesn't provide well calibrated probabilities.\n",
    "$$L(y,\\hat{f}) = \\max(0, 1-y\\hat{f})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-6, 6, 100);\n",
    "plt.plot(x, np.where(x < 1, 1 - x, 0));\n",
    "plt.xlabel(\"$-y\\hat{f}$\", size=18); plt.ylabel(\"$\\max(0,1-y\\hat{f})$\", size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exponential Loss\n",
    "\n",
    "- Used for Boosting.\n",
    "- Very susceptible to outliers.\n",
    " \n",
    "$$L(y,\\hat{f}) = \\exp(-y\\hat{f})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, 100);\n",
    "plt.plot(x, np.exp(-x));\n",
    "plt.xlabel(\"$-y\\hat{f}$\", size=18);\n",
    "plt.ylabel(\"$\\exp(-y\\hat{f})$\", size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loss Functions:  Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# adapted from http://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_loss_functions.html\n",
    "def plot_loss_functions():\n",
    "    xmin, xmax = -4, 4\n",
    "    xx = np.linspace(xmin, xmax, 100)\n",
    "    plt.plot(xx, xx ** 2, 'm-',\n",
    "             label=\"Quadratic loss\")\n",
    "    plt.plot([xmin, 0, 0, xmax], [1, 1, 0, 0], 'k-',\n",
    "             label=\"Zero-one loss\")\n",
    "    plt.plot(xx, 1/(1 + np.exp(xx)), 'b-',\n",
    "             label=\"Sigmoid loss\")\n",
    "    plt.plot(xx, np.where(xx < 1, 1 - xx, 0), 'g-',\n",
    "             label=\"Hinge loss\")\n",
    "    plt.plot(xx, np.log2(1 + np.exp(-xx)), 'r-',\n",
    "             label=\"Log loss\")\n",
    "    plt.plot(xx, np.exp(-xx), 'c-',\n",
    "             label=\"Exponential loss\")\n",
    "    plt.ylim((0, 8))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(r\"Decision function $f(x)$\")\n",
    "    plt.ylabel(\"$L(y, f)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Demonstrate some loss functions\n",
    "plot_loss_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Risk\n",
    "\n",
    "**Risk** is the expected loss or error.\n",
    "- Calculated differently for Bayesian vs. Frequentist Statistics\n",
    "\n",
    "For now, assume **quadratic loss** $L(y,\\hat{f}) = (y-\\hat{f})^2$\n",
    "- Associated risk is $R(\\hat{f}) = E_y[L(y, \\hat{f})] = E_y[(y-\\hat{f})^2]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias-Variance Decomposition\n",
    "\n",
    "- Can decompose the expected loss into a **bias** term and **variance** term.\n",
    "- Depending on samples, learning process can give different results\n",
    "    - ML vs MAP vs Posterior Mean, etc..\n",
    "- We want to learn a model with\n",
    "    - Small bias (how well a model fits the data on average)\n",
    "    - Small variance (how stable a model is w.r.t. data samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias-Variance Decomposition\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}[(y - \\hat{f})^2]\n",
    "&= \\mathbb{E}[y^2 - 2 \\cdot y \\cdot \\hat{f} + {\\hat{f}}^2] \\\\\n",
    "&= \\mathbb{E}[y^2] - \\mathbb{E}[2 \\cdot y \\cdot \\hat{f}] + \\mathbb{E}[{\\hat{f}}^2] \\\\\n",
    "&= \\mathrm{Var}[y] + {\\mathbb{E}[y]}^2 - \\mathbb{E}[2 \\cdot y \\cdot \\hat{f}] + \n",
    "   \\mathrm{Var}[\\hat{f}] + {\\mathbb{E}[{\\hat{f}}]}^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "since $Var[X] = \\mathbb{E}[{X}^2] - {\\mathbb{E}[X]}^2 \\implies \\mathbb{E}[X^2] = Var[X] + {\\mathbb{E}[X]}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias-Variance Decomposition\n",
    "\n",
    "$$\\begin{align} \\mathbb{E}[y] &= \\mathbb{E}[f + \\epsilon] \\\\\n",
    "               &= \\mathbb{E}[f] + \\mathbb{E}[\\epsilon] & \\text{ (linearity of expectations)}\\\\\n",
    "               &= \\mathbb{E}[f] + 0 &\\text{(zero-mean noise)}\\\\\n",
    "               &= f & \\text{ (} f \\text{ is determinstic)}\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias-Variance Decomposition\n",
    "\n",
    "$$\\begin{align} Var[y] &= \\mathbb{E}[(y - \\mathbb{E}[y])^2] \\\\\n",
    "                      &= \\mathbb{E}[(y - f)^2] \\\\\n",
    "                      &= \\mathbb{E}[(f + \\epsilon - f)^2] \\\\\n",
    "                      &= \\mathbb{E}[\\epsilon^2] \\equiv \\sigma^2 \\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias-Variance Decomposition\n",
    "\n",
    "We just showed that:\n",
    "- $\\mathbb{E}[y] = f$  \n",
    "- $\\mathrm{Var}[y] = \\mathbb{E}[\\epsilon^2] = \\sigma^2$\n",
    "                \n",
    "Therefore, \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}[(y - \\hat{f})^2]\n",
    "&= Var[y] + {\\mathbb{E}[y]}^2 - \\mathbb{E}[2 \\cdot y \\cdot \\hat{f} + Var[\\hat{f}] + {\\mathbb{E}[{\\hat{f}}]}^2 \\\\\n",
    "&= \\sigma^2 + f^2 - \\mathbb{E}[2 \\cdot y \\cdot \\hat{f}] + Var[\\hat{f}] + {\\mathbb{E}[{\\hat{f}}]}^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias-Variance Decomposition\n",
    "\n",
    "- Note $y$ is random ***only*** in $\\epsilon$ (again, $f$ is deterministic). \n",
    "- Also, $\\epsilon$ is ***independent*** from $\\hat{f}$.\n",
    "\n",
    "$\\begin{align}\\mathbb{E}[2 \\cdot y \\cdot \\hat{f}] \n",
    "                      &= \\mathbb{E}[2 \\cdot y \\cdot \\hat{f}]\\\\\n",
    "                      &= \\mathbb{E}[2 \\cdot y] \\cdot \\mathbb{E}[\\hat{f}] & \\text{ (by independence) }\\\\\n",
    "                      &= 2 \\cdot \\mathbb{E}[y] \\cdot \\mathbb{E}[\\hat{f}] \\\\\n",
    "                      &= 2 \\cdot f \\cdot \\mathbb{E}[\\hat{f}] \\end{align}$\n",
    "   \n",
    "Thus, we now have $\\mathbb{E}[(y - \\hat{f})^2] = \\sigma^2 + f^2 - 2 \\cdot f \\cdot \\mathbb{E}[\\hat{f}] + Var[\\hat{f}] + {\\mathbb{E}[{\\hat{f}}]}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias-Variance Decomposition\n",
    "\n",
    "$\\mathbb{E}[(y - \\hat{f})^2] = \\sigma^2 + Var[\\hat{f}] + f^2 - 2 \\cdot f \\cdot \\mathbb{E}[\\hat{f}] + {\\mathbb{E}[{\\hat{f}}]}^2$\n",
    "\n",
    "Now, $f^2 - 2 \\cdot f \\cdot \\mathbb{E}[\\hat{f}] + \\mathbb{E}[\\hat{f}]^2 = (f - \\mathbb{E}[\\hat{f}])^2$ \n",
    "\n",
    "$\\implies \\mathbb{E}[(y - \\hat{f})^2] = \\sigma^2 + Var[\\hat{f}] + (f - \\mathbb{E}[\\hat{f}])^2$\n",
    "\n",
    "$\\begin{align} \\text{Finally, } \\mathbb{E}[f - \\hat{f}] \n",
    "                        &= \\mathbb{E}[f] - \\mathbb{E}[\\hat{f}] \\text{ (linearity of expectations)} \\\\\n",
    "                        &= f - \\mathbb{E}[\\hat{f}] \\end{align}$\n",
    "                     \n",
    "So, $\\mathbb{E}[(y - \\hat{f})^2] = \\sigma^2 + Var[\\hat{f}] + {\\mathbb{E}[f - \\hat{f}]}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias-Variance Decomposition\n",
    "\n",
    "$\\mathbb{E}[(y - \\hat{f})^2] = \\underbrace{{\\sigma^2}}_\\text{irreducible error} + \\overbrace{{Var[\\hat{f}]}}^\\text{Variance} + \\underbrace{{\\mathbb{E}[f - \\hat{f}]}^2}_{\\text{Bias}^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias and Variance Formulae\n",
    "\n",
    "Bias of an estimator, $B(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta}] - \\theta$\n",
    "\n",
    "Variance of an estimator, $Var(\\hat{\\theta}) = \\mathbb{E}[(\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}])^2]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An example to explain Bias/Variance and illustrate the tradeoff \n",
    "\n",
    "- Consider estimating a sinusoidal function. \n",
    "\n",
    "(Example that follows is inspired by Yaser Abu-Mostafa's CS 156 Lecture titled \"Bias-Variance Tradeoff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "\n",
    "RANGEXS = np.linspace(0., 2., 300)\n",
    "TRUEYS = np.sin(np.pi * RANGEXS)\n",
    "\n",
    "def plot_fit(x, y, p, show,color='k'):\n",
    "    xfit = RANGEXS\n",
    "    yfit = np.polyval(p, xfit)\n",
    "    if show:\n",
    "        axes = pl.gca()\n",
    "        axes.set_xlim([min(RANGEXS),max(RANGEXS)])\n",
    "        axes.set_ylim([-2.5,2.5])\n",
    "        pl.scatter(x, y, facecolors='none', edgecolors=color)\n",
    "        pl.plot(xfit, yfit,color=color)\n",
    "        pl.hold('on')\n",
    "        pl.xlabel('x')\n",
    "        pl.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def calc_errors(p):\n",
    "    x = RANGEXS\n",
    "    errs = []\n",
    "    for i in x:\n",
    "        errs.append(abs(np.polyval(p, i) - np.sin(np.pi * i)) ** 2)\n",
    "    return errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_bias_variance(poly_coeffs, input_values_x, true_values_y):\n",
    "    # poly_coeffs: a list of polynomial coefficient vectors\n",
    "    # input_values_x: the range of xvals we will see\n",
    "    # true_values_y: the true labels/targes for y\n",
    "\n",
    "    # First we calculate the mean polynomial, and compute the predictions for this mean poly\n",
    "    mean_coeffs = np.mean(poly_coeffs, axis=0)\n",
    "    mean_predicted_poly = np.poly1d(mean_coeffs)\n",
    "    mean_predictions_y = np.polyval(mean_predicted_poly, input_values_x)\n",
    "    \n",
    "    # Then we calculate the error of this mean poly\n",
    "    bias_errors_across_x = (mean_predictions_y - true_values_y) ** 2\n",
    "    \n",
    "    # To consider the variance errors, we need to look at every output of the coefficients\n",
    "    variance_errors = []\n",
    "    for coeff in poly_coeffs:\n",
    "        predicted_poly = np.poly1d(coeff)\n",
    "        predictions_y = np.polyval(predicted_poly, input_values_x)\n",
    "        # Variance error is the average squared error between the predicted values of y\n",
    "        # and the *average* predicted value of y\n",
    "        variance_error = (mean_predictions_y - predictions_y)**2\n",
    "        variance_errors.append(variance_error)\n",
    "\n",
    "    variance_errors_across_x = np.mean(np.array(variance_errors),axis=0)\n",
    "    \n",
    "    return bias_errors_across_x, variance_errors_across_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.pylab import cm\n",
    "def polyfit_sin(degree=0, iterations=100, num_points=5, show=True):\n",
    "    total = 0\n",
    "    l = []\n",
    "    coeffs = []\n",
    "    errs = [0] * len(RANGEXS)\n",
    "    colors=cm.rainbow(np.linspace(0,1,iterations))\n",
    "    for i in range(iterations):\n",
    "        np.random.seed()\n",
    "        x = np.random.choice(RANGEXS,size=num_points) # Pick random points from the sinusoid\n",
    "        y = np.sin(np.pi * x)\n",
    "        p = np.polyfit(x, y, degree)  \n",
    "        y_poly = [np.polyval(p, x_i) for x_i in x]  \n",
    "        plot_fit(x, y, p, show,color=colors[i])\n",
    "        total += sum(abs(y_poly - y) ** 2) # calculate Squared Error (Squared Error) \n",
    "        coeffs.append(p)\n",
    "        errs = np.add(calc_errors(p), errs)\n",
    "    return total / iterations, errs / iterations, np.mean(coeffs, axis = 0), coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_bias_and_variance(biases,variances,range_xs,true_ys,mean_predicted_ys):\n",
    "    pl.plot(range_xs, mean_predicted_ys, c='k')\n",
    "    axes = pl.gca()\n",
    "    axes.set_xlim([min(range_xs),max(range_xs)])\n",
    "    axes.set_ylim([-3,3])\n",
    "    pl.hold('on')\n",
    "    pl.plot(range_xs, true_ys,c='b')\n",
    "    pl.errorbar(range_xs, mean_predicted_ys, yerr = biases, c='y', ls=\"None\", zorder=0,alpha=1)\n",
    "    pl.errorbar(range_xs, mean_predicted_ys, yerr = variances, c='r', ls=\"None\", zorder=0,alpha=0.1)\n",
    "    pl.xlabel('x')\n",
    "    pl.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's return to fitting polynomials\n",
    "\n",
    "* Here we generate some samples $x,y$, with $y = \\sin(2\\pi x)$\n",
    "* We then fit a *degree-0$ polynomial (i.e. a constant function) to the samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# polyfit_sin() generates 5 samples of the form (x,y) where y=sin(2*pi*x)\n",
    "# then it tries to fit a degree=0 polynomial (i.e. a constant func.) to the data\n",
    "# Ignore return values for now, we will return to these later\n",
    "_, _, _, _ = polyfit_sin(degree=0, iterations=1, num_points=5, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We can do this over many datasets\n",
    "\n",
    "* Let's sample a number of datasets\n",
    "* How does the fitted polynomial change for different datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Estimate two points of sin(pi * x) with a constant 5 times\n",
    "_, _, _, _ = polyfit_sin(0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about over lots more datasets?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Estimate two points of sin(pi * x) with a constant 100 times\n",
    "_, _, _, _ = polyfit_sin(0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "MSE, errs, mean_coeffs, coeffs_list = polyfit_sin(0, 100,num_points = 3,show=False)\n",
    "biases, variances = calculate_bias_variance(coeffs_list,RANGEXS,TRUEYS)\n",
    "plot_bias_and_variance(biases,variances,RANGEXS,TRUEYS,np.polyval(np.poly1d(mean_coeffs), RANGEXS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Decomposition: $\\mathbb{E}[(y - \\hat{f})^2] = \\underbrace{{\\sigma^2}}_\\text{irreducible error} + \\overbrace{{Var[\\hat{f}]}}^\\text{Variance} + \\underbrace{{\\mathbb{E}[f - \\hat{f}]}^2}_{\\text{Bias}^2}$\n",
    "* Blue curve: true $f$\n",
    "* Black curve: $\\hat f$, average predicted values of $y$\n",
    "* Yellow is error due to **Bias**, Red/Pink is error due to **Variance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bias vs. Variance\n",
    "* We can calculate how much error we suffered due to bias and due to variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "poly_degree = 0\n",
    "results_list = []\n",
    "MSE, errs, mean_coeffs, coeffs_list = polyfit_sin(\n",
    "    poly_degree, 500,num_points = 5,show=False)\n",
    "biases, variances = calculate_bias_variance(coeffs_list,RANGEXS,TRUEYS)\n",
    "sns.barplot(x='type', y='error',hue='poly_degree', data=pd.DataFrame([\n",
    "    {'error':np.mean(biases), 'type':'bias','poly_degree':0},\n",
    "    {'error':np.mean(variances), 'type':'variance','poly_degree':0}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's now fit degree=3 polynomials\n",
    "\n",
    "* Let's sample a dataset of 5 points and fit a cubic poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "MSE, _, _, _ = polyfit_sin(degree=3, iterations=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's now fit degree=3 polynomials\n",
    "\n",
    "* What does this look like over 5 different datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "_, _, _, _ = polyfit_sin(degree=3,iterations=5,num_points=5,show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's now fit degree=3 polynomials\n",
    "\n",
    "* What does this look like over 25 different datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Estimate two points of sin(pi * x) with a line 50 times\n",
    "_, _, _, _ = polyfit_sin(degree=3, iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "MSE, errs, mean_coeffs, coeffs_list = polyfit_sin(3,500,show=False)\n",
    "biases, variances = calculate_bias_variance(coeffs_list,RANGEXS,TRUEYS)\n",
    "plot_bias_and_variance(biases,variances,RANGEXS,TRUEYS,np.polyval(np.poly1d(mean_coeffs), RANGEXS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$\\mathbb{E}[(y - \\hat{f})^2] = \\underbrace{{\\sigma^2}}_\\text{irreducible error} + \\overbrace{{\\text{Var}[\\hat{f}]}}^\\text{Variance} + \\underbrace{{\\mathbb{E}[f - \\hat{f}]}^2}_{\\text{Bias}^2}$\n",
    "* Blue curve: true $f$\n",
    "* Black curve: $\\hat f$, average predicted values of $y$\n",
    "* Yellow is error due to **Bias**, Red/Pink is error due to **Variance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for poly_degree in [0,1,3]:\n",
    "    MSE, errs, mean_coeffs, coeffs_list = polyfit_sin(poly_degree,500,num_points=5,show=False)\n",
    "    biases, variances = calculate_bias_variance(coeffs_list,RANGEXS,TRUEYS)\n",
    "    results_list.append({'error':np.mean(biases),\n",
    "                         'type':'bias', 'poly_degree':poly_degree})\n",
    "    results_list.append({'error':np.mean(variances),\n",
    "                         'type':'variance', 'poly_degree':poly_degree})\n",
    "\n",
    "sns.barplot(x='type', y='error',hue='poly_degree',data=pd.DataFrame(results_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- Simpler Model (Constant)\n",
    " - High(er) Bias: $\\approx 0.45$\n",
    " - Low(er) Variance: $\\approx 0.23$\n",
    "- More Complex Model (Affine)\n",
    " - Low(er) Bias: $\\approx 0.32$\n",
    " - High(er) Variance: $\\approx 1.5$ ($ \\gg 0.25!)$\n",
    "\n",
    "Moral: (According to generalization performance) a constant is a better model than a linear model for approximating a sinusoid!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias Variance Tradeoff\n",
    "\n",
    "#### Central problem in supervised learning. \n",
    "\n",
    "Ideally, one wants to choose a model that both accurately captures the regularities in its training data, but also generalizes well to unseen data. Unfortunately, it is typically impossible to do both simultaneously. \n",
    "\n",
    "- High Variance: \n",
    " - Model represents the training set well. \n",
    " - Overfit to noise or unrepresentative training data. \n",
    " - Poor generalization performance\n",
    "\n",
    "\n",
    "- High Bias: \n",
    " - Simplistic models.\n",
    " - Fail to capture regularities in the data.\n",
    " - May give better generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpretations of Bias\n",
    " - Captures the errors caused by the simplifying assumptions of a model.\n",
    " - Captures the average errors of a model across different training sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpretations of Variance\n",
    " - Captures how much a learning method moves around the mean. \n",
    " - How different can one expect the hypotheses of a given model to be?\n",
    " - How sensitive is an estimator to different training sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Complexity of Model\n",
    "\n",
    "- Simple models generally have high bias and complex models generally have low bias. \n",
    "- Simple models generally have low variance andcomplex models generally have high variance.\n",
    "\n",
    "\n",
    "- Underfitting / Overfitting\n",
    " - High variance is associated with overfitting.\n",
    " - High bias is associated with underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training set size\n",
    " \n",
    "- Decreasing the training set size\n",
    " - Helps with a high bias algorithm: \n",
    "  - Will in general not help in improving performance. \n",
    "  - Can attain the same performance with smaller training samples however.\n",
    "  - Additional advantage of increases in speed.\n",
    "\n",
    "\n",
    "- Increase the training set size\n",
    " - Decreases Variance by reducing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Number of features\n",
    "- Increasing the number of features.\n",
    " - Decreases bias at the expense of increasing the variance.\n",
    "\n",
    "- Decreasing the number of features.\n",
    " - Dimensionality reduction can decrease variance by reducing over-fitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features \n",
    "\n",
    "Many techniques for engineering and selecting features (Feature Engineering and Feature Extraction)\n",
    " - PCA, Isomap, Kernel PCA, Autoencoders, Latent sematic analysis, Nonlinear dimensionality reduction, Multidimensional Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features\n",
    "\n",
    "The importance of features\n",
    " > \"Coming up with features is difficult, time-consuming, requires expert knowledge.  Applied machine learning is basically feature engineering\" \n",
    " - Andrew Ng\n",
    " \n",
    " \n",
    " > \"... some machine learning projects succeed and some fail.  What makes the difference? Easily the most important factor is the features used.\" \n",
    " - Pedro Domingo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regularization (Changing $\\lambda$)\n",
    "\n",
    "Regularization is designed to impose simplicity by adding a penalty term that depends on the charactistics of the parameters.\n",
    "\n",
    "- Decrease Regularization. \n",
    " - Reduces bias (allows the model to be more complex).\n",
    " \n",
    " \n",
    "- Increase Regularization.\n",
    " - Reduces variance by reducing overfitting (again, regularization imposes \"simplicity.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ideal bias and variance?\n",
    "\n",
    "- All is not lost. Bias and Variance can both be lowered through some methods:\n",
    " - Ex: Boosting (learning from weak classifiers).\n",
    "\n",
    "- The sweet spot for a model is the level of complexity at which the increase in bias is equivalent to the reduction in variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Selection \n",
    "\n",
    "- ML Algorithms generally have a lot of parameters that must be chosen. A natural question is then \"How do we choose them?\"\n",
    " - Examples: Penalty for margin violation (C), Polynomial Degree in polynomial fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Selection\n",
    "\n",
    "- Simple Idea: \n",
    " - Construct models $M_i, i = 1, ..., n$.\n",
    " - Train each of the models to get a hypothesis $h_i, i = 1, ..., n$.\n",
    " - Choose the best.\n",
    "- Does this work? No! Overfitting. This brings us to **cross validation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hold-Out Cross Validation \n",
    "\n",
    "(1) Randomly split the training data $D$ into $D_{train}$ and $D_{val}$, say 70% of the data and 30% of the data respectively.\n",
    "\n",
    "(2) Train each model $M_i$ on $D_{train}$ only, each time getting a hypothesis $h_i$.\n",
    "\n",
    "(3) Select and output hypothesis $h_i$ that had the smallest error on the held out validation set.\n",
    "\n",
    "Disadvantages: \n",
    " - Waste some sizable amount of data (30\\% in the above scenario) so that less training examples are available.\n",
    " - Using only some data for training and other data for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Fold Cross Validation (Step 1)\n",
    "\n",
    "Randomly split the training data $D$ into $K$ ***disjoint*** subsets of $N/K$ training samples each.\n",
    " - Let these subsets be denoted $D_1, ..., D_K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Fold Cross Validation (Step 2)\n",
    "\n",
    "For each model $M_i$, we evaluate the model as follows: \n",
    " - Train the model $M_i$ on $D \\setminus D_k$ (all of the subsets except subset $D_k$) to get hypothesis $h_i(k)$.\n",
    " - Test the hypothesis $h_i(k)$ on $D_k$ to get the error (or loss) $\\epsilon_i(k)$.\n",
    " - Estimated generalization error for model $M_i$ is then given by $e^g_i = \\frac{1}{K} \\sum \\limits_{k = 1}^K \\epsilon_i (k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Fold Cross Validation (Step 3)\n",
    "\n",
    "Pick the model $M_i^*$ with the lowest estimated generalization error $e^{g*}_i$ and retrain the model on the entire training set, thus giving the final hypothesis $h^*$ that is output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Three Way Data Splits\n",
    "\n",
    "- If model selection and true error estimates are to be computed simaltaneously, the data needs to be divided into three disjoin sets.\n",
    "\n",
    "- Training set: A set of examples used for learning\n",
    "- Validation set: A set of examples used to tune the hyperparameters of a classifier.\n",
    "- Test Set: A set of examples used *** only *** to assess the performance of a fully-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Procedure Outline\n",
    "\n",
    "1. Divide the available data into training, validation and test set\n",
    "2. Select a model (and hyperparameters)\n",
    "3. Train the model using the training set\n",
    "4. Evaluate the model using the validation set\n",
    "5. Repeat steps 2 through 4 using different models (and hyperparameters)\n",
    "6. Select the best model (and hyperparameter) and train it using data from the training and validation set\n",
    "7. Assess this final model using the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to choose hyperparameters?\n",
    "\n",
    "Cross Validation is only useful if we have some number of models. This often means constructing models each with a different combination of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Search\n",
    " - Just choose each hyperparameter randomly (possibly within some range for each.)\n",
    " - Pro: Easy to implement. Viable for models with a small number of hyperparameters and/or low dimensional data.\n",
    " - Con: Very inefficient for models with a large number of hyperparameters or high dimensional data (curse of dimensionality.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid Search / Parameter Sweep\n",
    " - Choose a subset for each of the parameters.\n",
    "  - Discretize real valued parameters with step sizes as necessary.\n",
    " - Output the model with the best cross validation performance. \n",
    " - Pro: \"Embarassingly Parallel\" (Can be easily parallelized)\n",
    " - Con: Again, curse of dimensionality poses problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Optimization\n",
    " \n",
    "- Assumes that there is a smooth but noisy relation that acts as a mapping from hyperparameters to the objective function.\n",
    "\n",
    "- Gather observations in such a manner as to evaluate the machine learning model the least number of times while revealing as much information as possible about the mapping and, in particular, the location of the optimum.\n",
    "\n",
    "- Exploration vs. Exploitation problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning Curves\n",
    "Provide a visualization for diagnostics such as:\n",
    "- Bias / variance\n",
    "- Convergence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Image from Andrew Ng's Stanford CS229 lecture titled \"Advice for applying machine learning\"\n",
    "from IPython.display import Image\n",
    "Image(filename='images/HighVariance.png', width=800, height=600)\n",
    "\n",
    "# Testing error still decreasing as the training set size increases. Suggests increasing the training set size.\n",
    "# Large gap Between Training and Test Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Image from Andrew Ng's Stanford CS229 lecture titled \"Advice for applying machine learning\"\n",
    "from IPython.display import Image\n",
    "Image(filename='images/HighBias.png', width=800, height=600)\n",
    "\n",
    "# Training error is unacceptably high.\n",
    "# Small gap between training error and testing error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convergence\n",
    "\n",
    "- Approach 1: \n",
    " - Measure gradient of the learning curve.\n",
    " - As learning curve gradient approaches 0, the model has been trained. Choose threshold to stop training.\n",
    "\n",
    "- Approach 2: \n",
    " - Measure change in the model parameters each iteration of the algorithm.\n",
    " - One can assume that training is complete when the change in model parameters is below some threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Diagnostics related to Convergence (1)\n",
    "- Convergence too slow? \n",
    " - Try using Newton's method.\n",
    " - Larger step size. \n",
    "  - Note that too large of a step size could also lead to slow convergence (but the learning curves in general will then suggest instability if \"oscillations\" are occuring.)\n",
    " - Decrease batch size if using a batch based optimization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics related to Convergence (2)\n",
    "\n",
    "- Are the learning curves stable? If not: \n",
    " - Switch to a batch style optimization algorithm if not already using one (like minibatch gradient descent / gradient descent).\n",
    " - Increase batch sizes if already using one.\n",
    "- Some algorithms always ensure a decrease or increase in the objective function each iterations. Ensure that this is the case if the optimization algorithm being used provides such guarantees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ablative Analysis\n",
    "\n",
    "- Similar to the idea of cross validation, except for components of a system.\n",
    "\n",
    "- Example: Simple Logisitic Regression on spam classification gives 94% performance.\n",
    " - 95% with spell correction\n",
    " - 96% with top 100 most commonly used words removed\n",
    " - 98% with extra sender and receiver information \n",
    " - 99% overall performance"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
